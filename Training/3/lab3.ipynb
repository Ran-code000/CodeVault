{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9934\n",
      "Precision: 0.9993\n",
      "Recall: 0.9909\n",
      "F1 Score: 0.9951\n",
      "Feature size: 1000\n",
      "Accuracy: 0.9913\n",
      "Precision: 0.9958\n",
      "Recall: 0.9912\n",
      "F1 Score: 0.9935\n",
      "--------------------------------------------------\n",
      "Feature size: 5000\n",
      "Accuracy: 0.9934\n",
      "Precision: 0.9993\n",
      "Recall: 0.9909\n",
      "F1 Score: 0.9951\n",
      "--------------------------------------------------\n",
      "Feature size: 10000\n",
      "Accuracy: 0.9934\n",
      "Precision: 0.9995\n",
      "Recall: 0.9906\n",
      "F1 Score: 0.9951\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 117\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data, labels\n\u001b[0;32m    116\u001b[0m \u001b[38;5;66;03m# 重新加载数据并进行训练\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m data_with_headers, labels \u001b[38;5;241m=\u001b[39m load_data_with_headers(data_path, label_path)\n\u001b[0;32m    118\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(data_with_headers, labels, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m    119\u001b[0m X_train_vec \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n",
      "Cell \u001b[1;32mIn[2], line 110\u001b[0m, in \u001b[0;36mload_data_with_headers\u001b[1;34m(data_path, label_path)\u001b[0m\n\u001b[0;32m    108\u001b[0m label, path \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m    109\u001b[0m email_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, path)\n\u001b[1;32m--> 110\u001b[0m email_content \u001b[38;5;241m=\u001b[39m load_email_content(email_path)\n\u001b[0;32m    111\u001b[0m email_header \u001b[38;5;241m=\u001b[39m extract_email_header(email_path)\n\u001b[0;32m    112\u001b[0m data\u001b[38;5;241m.\u001b[39mappend(email_content \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m email_header)  \u001b[38;5;66;03m# 合并正文和邮件头\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mload_email_content\u001b[1;34m(email_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_email_content\u001b[39m(email_path):\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(email_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<frozen codecs>:309\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, errors)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import re\n",
    "\n",
    "\n",
    "# 定义函数以加载邮件内容\n",
    "def load_email_content(email_path):\n",
    "    with open(email_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "    \n",
    "# 数据加载函数\n",
    "def load_data(data_path, label_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    # 读取标签文件\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, path = line.strip().split()\n",
    "            with open(os.path.join(data_path, path), 'r', encoding='utf-8') as email:\n",
    "                email_content = email.read()\n",
    "            data.append(email_content)\n",
    "            labels.append(label)\n",
    "    \n",
    "    return data, labels\n",
    "\n",
    "# 读取数据和标签\n",
    "# 使用原始字符串(r'...')\n",
    "data_path = r'C:\\Users\\Ran\\Desktop\\lab3data\\trec06c-utf8\\data_cut'  # 分词后的邮件目录\n",
    "label_path = r'C:\\Users\\Ran\\Desktop\\lab3data\\trec06c-utf8\\label\\index'  # 标签路径\n",
    "data, labels = load_data(data_path, label_path)\n",
    "\n",
    "# 数据划分为训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 文本特征提取\n",
    "vectorizer = CountVectorizer(max_features=5000)  # 选择最多5000个特征词\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# 训练朴素贝叶斯模型\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# 在测试集上进行预测\n",
    "y_pred = nb_model.predict(X_test_vec)\n",
    "\n",
    "# 计算性能指标\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "\n",
    "# 打印评估结果\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "\n",
    "# 测试不同词表大小对模型的影响\n",
    "feature_sizes = [1000, 5000, 10000]\n",
    "for size in feature_sizes:\n",
    "    vectorizer = CountVectorizer(max_features=size)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    # 训练并评估模型\n",
    "    nb_model.fit(X_train_vec, y_train)\n",
    "    y_pred = nb_model.predict(X_test_vec)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "    recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "    \n",
    "    print(f\"Feature size: {size}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "\n",
    "def extract_email_header(email_path):\n",
    "    with open(email_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "        headers = []\n",
    "        for line in lines:\n",
    "            if line.strip() == '':\n",
    "                break\n",
    "            headers.append(line.strip())\n",
    "    return \" \".join(headers)\n",
    "\n",
    "\n",
    "# 提取邮件头特征并将其与邮件正文结合\n",
    "def load_data_with_headers(data_path, label_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    headers = []\n",
    "    with open(label_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            label, path = line.strip().split()\n",
    "            email_path = os.path.join(data_path, path)\n",
    "            email_content = load_email_content(email_path)\n",
    "            email_header = extract_email_header(email_path)\n",
    "            data.append(email_content + \" \" + email_header)  # 合并正文和邮件头\n",
    "            labels.append(label)\n",
    "    return data, labels\n",
    "\n",
    "# 重新加载数据并进行训练\n",
    "data_with_headers, labels = load_data_with_headers(data_path, label_path)\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_with_headers, labels, test_size=0.2, random_state=42)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# 训练和评估模型\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "y_pred = nb_model.predict(X_test_vec)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label='spam')\n",
    "recall = recall_score(y_test, y_pred, pos_label='spam')\n",
    "f1 = f1_score(y_test, y_pred, pos_label='spam')\n",
    "\n",
    "print(f\"Accuracy with header info: {accuracy:.4f}\")\n",
    "print(f\"Precision with header info: {precision:.4f}\")\n",
    "print(f\"Recall with header info: {recall:.4f}\")\n",
    "print(f\"F1 Score with header info: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

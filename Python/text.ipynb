{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_names: ['blueWardsPlaced', 'blueWardsDestroyed', 'blueFirstBlood', 'blueKills', 'blueDeaths', 'blueAssists', 'blueEliteMonsters', 'blueDragons', 'blueHeralds', 'blueTowersDestroyed', 'blueTotalGold', 'blueAvgLevel', 'blueTotalExperience', 'blueTotalMinionsKilled', 'blueTotalJungleMinionsKilled', 'blueGoldDiff', 'blueExperienceDiff', 'blueCSPerMin', 'blueGoldPerMin', 'redWardsPlaced', 'redWardsDestroyed', 'redFirstBlood', 'redKills', 'redDeaths', 'redAssists', 'redEliteMonsters', 'redDragons', 'redHeralds', 'redTowersDestroyed', 'redTotalGold', 'redAvgLevel', 'redTotalExperience', 'redTotalMinionsKilled', 'redTotalJungleMinionsKilled', 'redGoldDiff', 'redExperienceDiff', 'redCSPerMin', 'redGoldPerMin']\n",
      "预测结果: [0 1 1 ... 1 0 1]\n",
      "accuracy: 0.7201\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 定义节点类\n",
    "class Node:\n",
    "    def __init__(self, feature=None, split=None, left=None, right=None, label=None):\n",
    "        self.feature = feature  # 当前节点分裂的特征索引\n",
    "        self.split = split  # 分裂阈值\n",
    "        self.left = left  # 左子节点\n",
    "        self.right = right  # 右子节点\n",
    "        self.label = label  # 如果是叶节点，存储类别\n",
    "        self.is_leaf = label is not None  # 判断是否是叶节点\n",
    "        \n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self, classes, features, max_depth=10, min_samples_split=2, impurity_t='gini', n_bins=10):\n",
    "        self.classes = classes\n",
    "        self.features = features\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.impurity_t = impurity_t\n",
    "        self.root = None\n",
    "        self.n_bins = n_bins  # 分箱数量\n",
    "\n",
    "    # 计算不纯度：支持gini和entropy\n",
    "    def impurity(self, label):\n",
    "        counts = np.bincount(label)\n",
    "        probabilities = counts / len(label)\n",
    "        if self.impurity_t == 'gini':\n",
    "            return 1 - np.sum(probabilities ** 2)  # 基尼指数\n",
    "        elif self.impurity_t == 'entropy':\n",
    "            return -np.sum(probabilities * np.log2(probabilities + 1e-10))  # 熵，避免log0\n",
    "        else:\n",
    "            raise ValueError(\"impurity_t should be 'gini' or 'entropy'\")\n",
    "\n",
    "    def find_best_split(self, feature, label):\n",
    "        best_gain = -1\n",
    "        best_feature, best_split = None, None\n",
    "        current_impurity = self.impurity(label)\n",
    "        n_features = feature.shape[1]\n",
    "        \n",
    "        for i in range(n_features):\n",
    "            unique_values = np.unique(feature[:, i])\n",
    "            thresholds = (unique_values[:-1] + unique_values[1:]) / 2\n",
    "            \n",
    "            for threshold in thresholds:\n",
    "                left_indices = feature[:, i] <= threshold\n",
    "                right_indices = ~left_indices\n",
    "                \n",
    "                if np.sum(left_indices) < 1 or np.sum(right_indices) < 1:\n",
    "                    continue\n",
    "                \n",
    "                left_impurity = self.impurity(label[left_indices])\n",
    "                right_impurity = self.impurity(label[right_indices])\n",
    "                gain = current_impurity - (\n",
    "                    len(label[left_indices]) / len(label) * left_impurity +\n",
    "                    len(label[right_indices]) / len(label) * right_impurity\n",
    "                )\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = i\n",
    "                    best_split = threshold\n",
    "        return best_feature, best_split\n",
    "\n",
    "    # 数据分裂\n",
    "    def split_data(self, feature, label, feature_idx, threshold):\n",
    "        left_indices = feature[:, feature_idx] <= threshold\n",
    "        right_indices = ~left_indices\n",
    "        return feature[left_indices], label[left_indices], feature[right_indices], label[right_indices]\n",
    "\n",
    "    # 创建叶节点\n",
    "    def create_leaf(self, label):\n",
    "        most_common_label = Counter(label).most_common(1)[0][0]\n",
    "        return Node(label=most_common_label)\n",
    "\n",
    "    def expand_node(self, feature, label, depth):\n",
    "        if len(np.unique(label)) == 1 or len(label) < self.min_samples_split or depth > self.max_depth:\n",
    "            return self.create_leaf(label)\n",
    "        \n",
    "        best_feature, best_split = self.find_best_split(feature, label)\n",
    "        if best_feature is None:\n",
    "            return self.create_leaf(label)\n",
    "        \n",
    "        left_feature, left_label, right_feature, right_label = self.split_data(feature, label, best_feature, best_split)\n",
    "        left_node = self.expand_node(left_feature, left_label, depth + 1)\n",
    "        right_node = self.expand_node(right_feature, right_label, depth + 1)\n",
    "        return Node(feature=best_feature, split=best_split, left=left_node, right=right_node)\n",
    "\n",
    "    def binning(self, feature):\n",
    "        \"\"\"\n",
    "        对特征进行等宽分箱\n",
    "        \"\"\"\n",
    "        binned_feature = np.zeros_like(feature)\n",
    "        for i in range(feature.shape[1]):\n",
    "            col = feature[:, i]\n",
    "            bins = np.linspace(col.min(), col.max(), self.n_bins + 1)\n",
    "            binned_feature[:, i] = np.digitize(col, bins[1:-1])\n",
    "        # print(\"分箱后的特征:\")\n",
    "        # print(binned_feature)  # 打印分箱后的特征数据\n",
    "        return binned_feature\n",
    "\n",
    "    def fit(self, feature, label):\n",
    "        assert len(self.features) == feature.shape[1], \"Feature count mismatch.\"\n",
    "        # print(\"训练数据特征:\")\n",
    "        # print(feature)  # 打印训练特征数据\n",
    "        # print(\"训练数据标签:\")\n",
    "        # print(label)  # 打印训练标签数据\n",
    "        # 在训练之前进行数据分箱\n",
    "        binned_feature = self.binning(feature)\n",
    "        self.root = self.expand_node(binned_feature, label, depth=1)\n",
    "\n",
    "    def predict(self, feature):\n",
    "        # 在预测之前也需要进行数据分箱\n",
    "        binned_feature = self.binning(feature)\n",
    "        if len(binned_feature.shape) == 1:\n",
    "            return self.traverse_node(self.root, binned_feature)\n",
    "        return np.array([self.traverse_node(self.root, sample) for sample in binned_feature])\n",
    "\n",
    "    # 预测单个样本\n",
    "    def traverse_node(self, node, sample):\n",
    "        if node.is_leaf:\n",
    "            return node.label\n",
    "        if sample[node.feature] <= node.split:\n",
    "            return self.traverse_node(node.left, sample)\n",
    "        else:\n",
    "            return self.traverse_node(node.right, sample)\n",
    "\n",
    "\n",
    "# 测试代码\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 加载自己的数据集\n",
    "    data = pd.read_csv(\"data.csv\", sep=\"\\t\")\n",
    "    \n",
    "    #print(repr(data.columns))  # 打印列名的详细信息\n",
    "    # 假设 'blueWins' 是标签列，表示蓝方是否获胜\n",
    "    X = data.drop(columns=[\"gameId\", \"blueWins\"]).values  # 删除 'gameId' 和 'blueWins' 列，作为特征\n",
    "    y = data[\"blueWins\"].values  # 'blueWins' 列是目标标签，表示蓝方是否获胜\n",
    "    \n",
    "    # 获取特征名称（不包括目标列）\n",
    "    feature_names = data.columns.drop([\"gameId\", \"blueWins\"]).tolist()\n",
    "    print(\"feature_names:\", feature_names)\n",
    "    \n",
    "    # 划分训练集和测试集，80% 训练集，20% 测试集\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # 定义决策树模型，包括分箱数量\n",
    "    DT = DecisionTree(classes=[0, 1], features=feature_names, max_depth=2, min_samples_split=3, impurity_t='gini', n_bins=10)\n",
    "    DT.fit(x_train, y_train)  # 训练模型\n",
    "    p_test = DT.predict(x_test)  # 预测测试集\n",
    "    \n",
    "    # 输出预测结果及准确率\n",
    "    print(\"预测结果:\", p_test)\n",
    "    test_acc = accuracy_score(p_test, y_test)\n",
    "    print(\"accuracy: {:.4f}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
